[main]
# the parent directory for all the test suite stuff.  The benchmarks
# and run directories will live under here
testTopDir     = /path/to/IAMR

# location of the tests' output, written in html
webTopDir      = /path/to/html/results/

MAKE = make
sourceTree = C_Src
# how many simultaneous build jobs (through the -j flag of make) are to
# be done
numMakeJobs = 8

# the names of the compilers for C++ and Fortran.  These should be
# names that the AMReX build system can interpret, as these variables
# as passed directly to the make command.
COMP = g++
FCOMP = gfortran

# additional options added to C++ make command
add_to_c_make_command = TEST=TRUE USE_ASSERTION=TRUE

# after the test is run and the comparisons are made, do we keep the
# plotfiles around?  If this is 1, then any plot or checkpoint files,
# except the one that was used for the comparison will be deleted.
# Otherwise, all the output files will be tar/gzipped.
purge_output = 1

# suiteName is the name prepended to all output directories
suiteName = IAMR

# should the main test webpage only include columns for tests that are
# defined in the inputs file?  This can be used to filter out any 
# old test names that might exist in older test runs, but are no 
# longer tests that are actively run.
reportActiveTestsOnly = 1

# Add "GO UP" link at the top of the web page?
goUpLink = 1

# email
sendEmailWhenFail = 0
#emailTo = user1@address1.com, user2@address2.com
#emailBody = Check https://ccse.lbl.gov/pub/RegressionTesting/IAMR/ for more details.

# MPIcommand should use the placeholders:
#   @host@ to indicate where to put the hostname to run on
#   @nprocs@ to indicate where to put the number of processors
#   @command@ to indicate where to put the command to run
#
# only tests with useMPI = 1 will run in parallel
# nprocs is problem dependent and specified in the individual problem
# sections.

#MPIcommand = mpiexec -host @host@ -n @nprocs@ @command@
MPIcommand = mpiexec -n @nprocs@ @command@
MPIhost = 

# Specify the source code repositories.  Each git repo is
# given its own section.  

[AMReX]
# This should be a separate directoy from one you do
# day-to-day work in, to ensure that there are no conflicts
# when the test suite does git pulls
dir = /path/to/scratch/amrex/clone
branch = development

[source]
dir = /path/to/scratch/IAMR/clone
branch = development

[extra-AMReX-Hydro]
dir = /home/regtester/git/AMReX-Hydro
branch = main

# individual problems follow

#-----------------------------------------
# particle
#-----------------------------------------
[Part-2d] 
buildDir = Exec/run_2d_particles/
inputFile = regtest.inputs
aux1File = particle_file
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 0
compileTest = 0
doVis = 0
diffDir = particle_dir
compareParticles=1
particleTypes=Particles
particle_tolerance=1e-12
tolerance = 9.99e-11

#-----------------------------------------
# Regular geometry (i.e. non-EB)
#-----------------------------------------
[Euler] 
buildDir = Exec/run3d/
inputFile = regtest.3d.euler
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[Euler_restart] 
buildDir = Exec/run3d/
inputFile = regtest.3d.euler-restart
dim = 3
restartTest = 1
restartFileNum = 6
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[TaylorGreen]
buildDir = Exec/run3d/
inputFile = regtest.3d.taylorgreen
dim = 3
restartTest = 0
useMPI = 1
numprocs = 4
useOMP = 0
numthreads = 2
compileTest = 0
doVis = 0

[HotSpot]
buildDir = Exec/run3d/
inputFile = regtest.3d.hotspot
dim = 3
restartTest = 0
useMPI = 1
numprocs = 4
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[HotSpot-2d]
buildDir = Exec/run2d/
inputFile = regtest.2d.hotspot
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[HotSpot-2d_MOL]
buildDir = Exec/run2d/
inputFile = regtest.2d.hotspot_MOL
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[Poiseuille_2d]
buildDir = Exec/run2d/
inputFile = regtest.2d.poiseuille
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[Bubble_MOL]
buildDir = Exec/run2d/
inputFile = regtest.2d.bubble_MOL
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[Bubble_rz]
buildDir = Exec/run2d/
inputFile = regtest.2d.bubble_rz
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[BDS_tracer_advection_2d]
buildDir = Exec/run2d/
inputFile = regtest.2d.traceradvect_bds
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[BDS_tracer_advection]
buildDir = Exec/run3d/
inputFile = regtest.3d.traceradvect_bds
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[RayleighTaylor]
buildDir = Exec/run3d/
inputFile = regtest.3d.rayleightaylor
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[Poiseuille] 
buildDir = Exec/run3d/
inputFile = regtest.3d.poiseuille
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[LidDrivenCavity] 
buildDir = Exec/run3d/
inputFile = regtest.3d.lid_driven_cavity
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

#-----------------------------------------------------
# EB tests
#-----------------------------------------------------
[FlowPastCylinder-x_2d] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.flow_past_cylinder-x
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FlowPastCylinder-y_2d] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.flow_past_cylinder-y
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[EBhotspot_2d] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.hotspot
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[EBhotspot_2d_MOL] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.hotspot_MOL
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[EBbubble] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.bubble
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[DoubleShearLayer_2d] 
buildDir = Exec/eb_run2d/
inputFile = regtest.2d.double_shear_layer
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FlowPastCylinder-x] 
buildDir = Exec/eb_run3d/
inputFile = regtest.3d.flow_past_cylinder-x
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FlowPastCylinder-y] 
buildDir = Exec/eb_run3d/
inputFile = regtest.3d.flow_past_cylinder-y
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FlowPastCylinder-z] 
buildDir = Exec/eb_run3d/
inputFile = regtest.3d.flow_past_cylinder-z
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[EBhotspot] 
buildDir = Exec/eb_run3d/
inputFile = regtest.3d.hotspot
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[DoubleShearLayer] 
buildDir = Exec/eb_run3d/
inputFile = regtest.3d.double_shear_layer
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0
